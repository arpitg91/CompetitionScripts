{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train!\n",
      "Train read!\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import gc\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "print ('Reading train!')\n",
    "train = pd.read_csv('/data/arpit.goel/18_InventoryPrediction/02.ExtractedData/train.csv',\n",
    "                    usecols=['Agencia_ID',\n",
    "                                  'Ruta_SAK',\n",
    "                                  'Cliente_ID',\n",
    "                                  'Producto_ID',\n",
    "                                  'Demanda_uni_equil'],\n",
    "                    dtype={'Agencia_ID': 'uint16',\n",
    "                                      'Ruta_SAK': 'uint16',\n",
    "                                      'Cliente_ID': 'int32',\n",
    "                                      'Producto_ID': 'uint16',\n",
    "                                      'Demanda_uni_equil': 'float32'})\n",
    "print ('Train read!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating means features\n",
      "Transformed DuE\n",
      "Got MeanP\n",
      "Got MeanC\n",
      "Got MeanPA\n",
      "Got MeanPR\n",
      "Got MeanPCA\n",
      "Dropping duplicates!\n"
     ]
    }
   ],
   "source": [
    "print ('Estimating means features')\n",
    "train['Demanda_uni_equil'] = train['Demanda_uni_equil'].apply(lambda x: 1.005*np.log1p(x + 0.01) - 0.005)\n",
    "mean = train['Demanda_uni_equil'].mean()\n",
    "print ('Transformed DuE')\n",
    "train['MeanP'] = train.groupby('Producto_ID')['Demanda_uni_equil'].transform(np.mean).astype('float32')\n",
    "print ('Got MeanP')\n",
    "train['MeanC'] = train.groupby('Cliente_ID')['Demanda_uni_equil'].transform(np.mean).astype('float32')\n",
    "print ('Got MeanC')\n",
    "train['MeanPA'] = train.groupby(['Producto_ID',\n",
    "                                 'Agencia_ID'])['Demanda_uni_equil'].transform(np.mean).astype('float32')\n",
    "print ('Got MeanPA')\n",
    "train['MeanPR'] = train.groupby(['Producto_ID',\n",
    "                                 'Ruta_SAK'])['Demanda_uni_equil'].transform(np.mean).astype('float32')\n",
    "print ('Got MeanPR')\n",
    "train['MeanPCA'] = train.groupby(['Producto_ID',\n",
    "                                  'Cliente_ID',\n",
    "                                  'Agencia_ID'])['Demanda_uni_equil'].transform(np.mean).astype('float32')\n",
    "print ('Got MeanPCA')\n",
    "train.drop_duplicates(subset=['Agencia_ID', 'Cliente_ID', 'Ruta_SAK', 'Producto_ID'], inplace=True)\n",
    "\n",
    "print ('Dropping duplicates!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "MPCA = train.loc[:, ['Producto_ID', 'Agencia_ID', 'Cliente_ID', 'MeanPCA']].drop_duplicates(subset=['Agencia_ID', 'Cliente_ID', 'Producto_ID'])\n",
    "print ('1')\n",
    "MPA = train.loc[:, ['Producto_ID', 'Agencia_ID', 'MeanPA']].drop_duplicates(subset=['Agencia_ID', 'Producto_ID'])\n",
    "print ('2')\n",
    "MC = train.loc[:, ['Cliente_ID','MeanC']].drop_duplicates(subset=['Cliente_ID'])\n",
    "print ('3')\n",
    "MP = train.loc[:, ['Producto_ID', 'MeanP']].drop_duplicates(subset=['Producto_ID'])\n",
    "print ('4')\n",
    "MPR = train.loc[:, ['Producto_ID', 'Ruta_SAK', 'MeanPR']].drop_duplicates(subset=['Ruta_SAK', 'Producto_ID'])\n",
    "print ('5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Test\n",
      "Test read!\n",
      "Merging!\n",
      "PCA merged!\n",
      "PA merged!\n",
      "C merged!\n",
      "P merged\n",
      "PR merged\n",
      "Merging done!\n",
      "(6999251, 10)\n"
     ]
    }
   ],
   "source": [
    "print ('Reading Test')\n",
    "test = pd.read_csv('/data/arpit.goel/18_InventoryPrediction/02.ExtractedData/test.csv',\n",
    "                   usecols=['Agencia_ID',\n",
    "                              'Ruta_SAK',\n",
    "                              'Cliente_ID',\n",
    "                              'Producto_ID',\n",
    "                            'id'],\n",
    "                   dtype={'Agencia_ID': 'uint16',\n",
    "                                      'Ruta_SAK': 'uint16',\n",
    "                                      'Cliente_ID': 'int32',\n",
    "                                      'Producto_ID': 'uint16',\n",
    "                                      'id': 'int32'})\n",
    "print ('Test read!')\n",
    "print ('Merging!')\n",
    "test = test.merge(MPCA,\n",
    "                  how='left',\n",
    "                  on=['Producto_ID', 'Agencia_ID', 'Cliente_ID'],\n",
    "                  copy=False)\n",
    "print ('PCA merged!')\n",
    "test = test.merge(MPA,\n",
    "                  how='left',\n",
    "                  on=['Producto_ID', 'Agencia_ID'],\n",
    "                  copy=False)\n",
    "print ('PA merged!')\n",
    "test = test.merge(MC,\n",
    "                  how='left',\n",
    "                  on=['Cliente_ID'],\n",
    "                  copy=False)\n",
    "print ('C merged!')\n",
    "test = test.merge(MP,\n",
    "                  how='left',\n",
    "                  on=['Producto_ID'],\n",
    "                  copy=False)\n",
    "print ('P merged')\n",
    "test = test.merge(MPR,\n",
    "                  how='left',\n",
    "                  on=['Producto_ID', 'Ruta_SAK'],\n",
    "                  copy=False)\n",
    "print ('PR merged')\n",
    "\n",
    "print ('Merging done!')\n",
    "print (test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.loc[:, 'Demanda_uni_equil'] = test.loc[:, 'MeanPCA'].apply(np.expm1)*0.723 +\\\n",
    "                            test.loc[:, 'MeanPR'].apply(np.expm1)*0.194 + 0.091\n",
    "indeks = test['Demanda_uni_equil'].isnull()\n",
    "test.loc[indeks, 'Demanda_uni_equil'] = test.loc[indeks, 'MeanPR'].apply(np.expm1)*0.746 + 0.17\n",
    "indeks = test['Demanda_uni_equil'].isnull()\n",
    "test.loc[indeks, 'Demanda_uni_equil'] = test.loc[indeks, 'MeanC'].apply(np.expm1)*0.82 + 0.86\n",
    "indeks = test['Demanda_uni_equil'].isnull()\n",
    "test.loc[indeks, 'Demanda_uni_equil'] = test.loc[indeks, 'MeanPA'].apply(np.expm1)*0.54 + 0.8\n",
    "indeks = test['Demanda_uni_equil'].isnull()\n",
    "test.loc[indeks, 'Demanda_uni_equil'] = test.loc[indeks, 'MeanP'].apply(np.expm1)*0.44 + 1\n",
    "indeks = test['Demanda_uni_equil'].isnull()\n",
    "test.loc[indeks, 'Demanda_uni_equil'] = np.expm1(mean)\n",
    "test.loc[:, ['id', 'Demanda_uni_equil']].to_csv('/data/arpit.goel/18_InventoryPrediction/05.Submissions/submission_public_script1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           1.087151\n",
       "1           1.102295\n",
       "2           1.154137\n",
       "3           1.521830\n",
       "4           1.476789\n",
       "5           1.502108\n",
       "6           1.279126\n",
       "7           1.743002\n",
       "8           1.732456\n",
       "9           2.520366\n",
       "10          1.801308\n",
       "11          1.423805\n",
       "12          2.140671\n",
       "13          1.852354\n",
       "14          1.747349\n",
       "15          2.176181\n",
       "16          1.484711\n",
       "17          1.469339\n",
       "18          2.258018\n",
       "19          1.605822\n",
       "20          1.756621\n",
       "21          1.213807\n",
       "22          2.014619\n",
       "23          1.716188\n",
       "24          1.557080\n",
       "25          1.332082\n",
       "26          1.557080\n",
       "27          0.959698\n",
       "28          1.332082\n",
       "29          1.157976\n",
       "              ...   \n",
       "74180427    1.203060\n",
       "74180430    1.143278\n",
       "74180431    1.711345\n",
       "74180432    1.329460\n",
       "74180433    1.297095\n",
       "74180434    1.154474\n",
       "74180435    1.667817\n",
       "74180436    1.035590\n",
       "74180437    1.300450\n",
       "74180439    1.667817\n",
       "74180440    1.439111\n",
       "74180441    1.143278\n",
       "74180442    1.711345\n",
       "74180443    1.154474\n",
       "74180444    1.453260\n",
       "74180445    1.667817\n",
       "74180446    1.439111\n",
       "74180448    1.154474\n",
       "74180449    1.667817\n",
       "74180450    1.439111\n",
       "74180451    1.035590\n",
       "74180453    1.329561\n",
       "74180454    1.257141\n",
       "74180455    1.203060\n",
       "74180456    1.588361\n",
       "74180458    1.536882\n",
       "74180459    1.667817\n",
       "74180460    1.439111\n",
       "74180461    1.154474\n",
       "74180463    1.329460\n",
       "dtype: float32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train['MeanP'] = train.groupby('Producto_ID')['Demanda_uni_equil'].transform(np.mean).astype('float32')\n",
    "train.groupby('Producto_ID')['Demanda_uni_equil'].transform(np.mean).astype('float32')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
