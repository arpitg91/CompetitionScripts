{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os,sys,string,re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    \n",
    "def clean_category(x):\n",
    "    if len(x)==0:\n",
    "        return ''\n",
    "    x=re.sub(chr(195),'e',x)\n",
    "    x=re.sub(chr(169),'',x)\n",
    "    x=x.translate(trans)\n",
    "    x=re.sub(' +',' ',x)\n",
    "    x=x.lower()\n",
    "    x=' '.join(list(set(map(ps.stem,x.split(' ')))))\n",
    "    x=re.sub('(\\\\b[A-Za-z] \\\\b|\\\\b [A-Za-z]\\\\b)', '',x)\n",
    "    return x\n",
    "def clean_brand(x):\n",
    "    return re.sub('[^0-9a-z]','',x.lower())\n",
    "def get_cat_lookup(df):\n",
    "    cat_lookup=df.groupby('category_name')['log_price'].apply(lambda x: {'log_price':x.sum(),'count':x.size}).unstack()\n",
    "    cat_lookup['category_name']=cat_lookup.index\n",
    "    cat_lookup['category0']=cat_lookup['category_name'].map(lambda x: str(x).split('/')[0]).map(clean_category)\n",
    "    cat_lookup['category1']=cat_lookup['category_name'].map(lambda x: str(x).split('/')[1] if str(x).count('/')>=1 else 'na').map(clean_category)\n",
    "    cat_lookup['category2']=cat_lookup['category_name'].map(lambda x: str(x).split('/')[2] if str(x).count('/')>=2 else 'na').map(clean_category)    \n",
    "    return cat_lookup\n",
    "def get_group_lookup(df,cols,label,threshold):\n",
    "    interaction_num=len(cols)\n",
    "    df_group=df.groupby(cols)['log_price'].apply(lambda x: {'count':x.size,'sum_log_price':x.sum()}).unstack().reset_index()\n",
    "    df_group['new_grp']=np.where(df_group['count']>threshold,df_group.index,-999)\n",
    "    df_index_group=df_group.groupby('new_grp')[['count','sum_log_price']].sum()\n",
    "    df_index_group['freq']=df_index_group['count']/df_index_group['count'].sum()\n",
    "    df_index_group['avg_log_price']=df_index_group['sum_log_price']/df_index_group['count']\n",
    "    df_group['sig%d_%d_freq'%(len(cols),label)]=df_group['new_grp'].map(df_index_group['freq'])\n",
    "    df_group['sig%d_%d_price'%(len(cols),label)]=df_group['new_grp'].map(df_index_group['avg_log_price'])\n",
    "    df_group=df_group[df_group['new_grp']>=0]\n",
    "    output_sigs=[x for x in df_group.columns if 'sig' in x]\n",
    "    missing_vals=[0,df['log_price'].mean()] if -999 not in df_index_group.index else list(df_index_group.ix[-999,['freq','avg_log_price']])\n",
    "    missing_vals=pd.Series(missing_vals,index=output_sigs)\n",
    "    return df_group[cols+output_sigs],missing_vals\n",
    "def get_group_lookups(df):\n",
    "    interaction_columns=['category0','category1','category2','brand']\n",
    "    brand_cat_space=[list(x) for i in range(len(interaction_columns)) for x in combinations(interaction_columns,i+1)]\n",
    "    group_lookups={}\n",
    "    for i,x in enumerate(brand_cat_space):\n",
    "        group_lookups[tuple(x)]=get_group_lookup(df,x,i,50)\n",
    "    return group_lookups\n",
    "def clean_cat_brand(df):\n",
    "    df['category0']=df['category_name'].astype(np.str).map(cat_lookup['category0']).fillna('nan')\n",
    "    df['category1']=df['category_name'].astype(np.str).map(cat_lookup['category1']).fillna('nan')\n",
    "    df['category2']=df['category_name'].astype(np.str).map(cat_lookup['category2']).fillna('nan')\n",
    "    df['brand']=df['brand_name'].fillna('nan').astype(np.str).map(clean_brand)\n",
    "    return df\n",
    "def get_cat_brand_vars(df):\n",
    "    interaction_columns=['category0','category1','category2','brand']\n",
    "    for i,x in group_lookups.items():\n",
    "        df=pd.merge(df,x[0],on=list(i),how='outer')\n",
    "        df.fillna(x[1],inplace=True)\n",
    "    for i in range(len(interaction_columns)):\n",
    "        for signal in ['freq','price']:\n",
    "            signals=[x for x in df.columns if 'sig%d'%(i+1) in x and signal in x]\n",
    "            df['sig%d_max_%s'%(i+1,signal)]=df[signals].max(axis=1)\n",
    "            df['sig%d_min_%s'%(i+1,signal)]=df[signals].min(axis=1)\n",
    "            df['sig%d_avg_%s'%(i+1,signal)]=df[signals].mean(axis=1)\n",
    "    df['cost_in_description']=df['item_description'].astype(np.str).map(lambda x: 1 if '[rm]' in x else 0)\n",
    "    return df\n",
    "def get_free_text_vars(df,var,label):\n",
    "    df['ft_0_%s'%label]=df[var].astype(np.str).str.len()                                                             # Num characters\n",
    "    df['ft_1_%s'%label]=df[var].astype(np.str).map(lambda x: re.sub('[%s]'%string.printable,'',x)).str.len()         # Num non printable chars\n",
    "    df['ft_2_%s'%label]=df[var].astype(np.str).map(lambda x: re.sub('[^#$%&*:;<=>?@\\^_`|~]','',x)).str.len()         # Num Special Characters\n",
    "    df['ft_3_%s'%label]=df[var].astype(np.str).map(lambda x: re.sub('[^0-9]','',x)).str.len()                        # Num numerals\n",
    "    df['ft_4_%s'%label]=df[var].astype(np.str).map(lambda x: re.sub('[^a-z]','',x)).str.len()                        # Num lower case\n",
    "    df['ft_5_%s'%label]=df[var].astype(np.str).map(lambda x: re.sub('[^A-Z]','',x)).str.len()                        # Num upper case\n",
    "    df['ft_6_%s'%label]=df[var].astype(np.str).map(lambda x: re.sub('[^ ]','',x)).str.len()                          # Num spaces\n",
    "    df['%s_clean'%label]=df[var].astype(np.str).str.lower().map(lambda x: re.sub('[^ a-z]',' ',x))                   # Clean Text\n",
    "    return df\n",
    "def clean_text(df):\n",
    "    df['free_text']=df['name_clean']+' '+df['desc_clean']\n",
    "    df['free_text']=df['free_text'].map(lambda x: ' '.join([keywords_lookup[y] for y in x.split(' ') if y in keywords_raw]))\n",
    "    return df\n",
    "def stem_word(x):\n",
    "    try:\n",
    "        return ps.stem(x)\n",
    "    except:\n",
    "        return x\n",
    "def get_vocabulary(df):\n",
    "    all_words=pd.concat([df['name'],df['item_description']]).values\n",
    "    all_words=[re.sub('[^ a-z]',' ',y.lower()) for x in all_words for y in str(x).split()]\n",
    "    all_words=pd.Series(Counter(all_words))\n",
    "    all_words=all_words[all_words>100]\n",
    "    stemmed_words=all_words.reset_index()\n",
    "    stemmed_words.columns=['word','count']\n",
    "    stemmed_words['stem']=stemmed_words['word'].map(stem_word)\n",
    "    stemmed_words.index=stemmed_words['word']\n",
    "    vocabulary=stemmed_words.groupby('stem')['count'].sum()\n",
    "    vocabulary=vocabulary[vocabulary>=100].index.tolist()\n",
    "    keywords_raw=set(stemmed_words['word'])\n",
    "    keywords_lookup=stemmed_words['stem'].to_dict()\n",
    "    return vocabulary,keywords_raw,keywords_lookup\n",
    "def get_tfidf_predictions(datasets,column,num_features,output_column):\n",
    "    vectorizer = TfidfVectorizer(max_features=num_features) if num_features>0 else TfidfVectorizer()\n",
    "    vectorizer.fit(datasets[0][column].fillna('nan'))\n",
    "    ft_features=[vectorizer.transform(data[column].fillna('nan')) for data in datasets]\n",
    "    model = Ridge(alpha=0.1,solver='sag')\n",
    "    model.fit(ft_features[0],datasets[0]['log_price'])\n",
    "    for i,ft_feature in enumerate(ft_features):\n",
    "        datasets[i][output_column]=model.predict(ft_feature)\n",
    "    return datasets\n",
    "def get_tfidf_matrix(datasets,column,num_features):\n",
    "    vectorizer = TfidfVectorizer(max_features=num_features) if num_features>0 else TfidfVectorizer()\n",
    "    vectorizer.fit(datasets[0][column].fillna('nan'))\n",
    "    ft_features=[vectorizer.transform(data[column].fillna('nan')) for data in datasets]\n",
    "    return ft_features\n",
    "def get_ridge_predictions(datasets,matrix,output_column):\n",
    "    model = Ridge(alpha=0.1,solver='sag')\n",
    "    model.fit(matrix[0],datasets[0]['log_price'])\n",
    "    for i,ft_feature in enumerate(matrix):\n",
    "        datasets[i][output_column]=model.predict(ft_feature)\n",
    "    return datasets    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1157560\n",
       "True       28468\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ins['price']<5).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#if __name__=='__main__':\n",
    "if 1==1:\n",
    "    to_space= '''&,()+'\"/'''\n",
    "    trans=str.maketrans(to_space, ' '*len(to_space)) #Change to str when submitting\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    os.chdir('/data/arpit.goel/31_PricePrediction/03.Submissions')  #Remove while sumbitting\n",
    "    pd.set_option('display.float_format', lambda x: '%.1f' % x)\n",
    "\n",
    "    df_raw_train=pd.read_csv('../input/train.tsv',delimiter='\\t')\n",
    "    df_raw_test=pd.read_csv('../input/test.tsv',delimiter='\\t')\n",
    "    df_raw_train['log_price']=np.log(1+df_raw_train['price'])\n",
    "    #df_raw_train=df_raw_train[df_raw_train['log_price']>1]\n",
    "    ins=df_raw_train.sample(frac=0.8,random_state=200) #Change to 95/99 percent when submitting\n",
    "    oos=df_raw_train.drop(ins.index)\n",
    "    oot=df_raw_test\n",
    "    datasets=[ins,oos,oot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0         874\n",
       "3.0       18703\n",
       "4.0       16139\n",
       "5.0       31502\n",
       "5.5          33\n",
       "6.0       32260\n",
       "6.5          16\n",
       "7.0       52268\n",
       "7.5          34\n",
       "8.0       61564\n",
       "8.5          20\n",
       "9.0       63643\n",
       "9.5          17\n",
       "10.0      99416\n",
       "10.5         38\n",
       "11.0      39786\n",
       "11.5         13\n",
       "12.0      78986\n",
       "12.5         34\n",
       "13.0      36800\n",
       "13.5          4\n",
       "14.0      76655\n",
       "14.5         13\n",
       "15.0      58082\n",
       "15.5         12\n",
       "16.0      66413\n",
       "16.5          7\n",
       "17.0      21334\n",
       "17.5          8\n",
       "18.0      41243\n",
       "          ...  \n",
       "1506.0        1\n",
       "1509.0        1\n",
       "1515.0        1\n",
       "1525.0        2\n",
       "1528.0        1\n",
       "1550.0        1\n",
       "1575.0        1\n",
       "1600.0        3\n",
       "1609.0        1\n",
       "1615.0        1\n",
       "1625.0        1\n",
       "1700.0        1\n",
       "1708.0        1\n",
       "1709.0        1\n",
       "1747.0        1\n",
       "1750.0        1\n",
       "1759.0        1\n",
       "1770.0        1\n",
       "1800.0        3\n",
       "1806.0        2\n",
       "1808.0        1\n",
       "1815.0        2\n",
       "1850.0        2\n",
       "1900.0        1\n",
       "1909.0        1\n",
       "1999.0        1\n",
       "2000.0        6\n",
       "2004.0        1\n",
       "2006.0        1\n",
       "2009.0        1\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_train['price'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train_id                    0\n",
      "name                        0\n",
      "item_condition_id           0\n",
      "category_name            5029\n",
      "brand_name             506217\n",
      "price                       0\n",
      "shipping                    0\n",
      "item_description            4\n",
      "log_price                   0\n",
      "category0                   0\n",
      "category1                   0\n",
      "category2                   0\n",
      "brand                       0\n",
      "sig3_10_freq                0\n",
      "sig3_10_price               0\n",
      "sig3_11_freq                0\n",
      "sig3_11_price               0\n",
      "sig2_5_freq                 0\n",
      "sig2_5_price                0\n",
      "sig1_0_freq                 0\n",
      "sig1_0_price                0\n",
      "sig4_14_freq                0\n",
      "sig4_14_price               0\n",
      "sig2_9_freq                 0\n",
      "sig2_9_price                0\n",
      "sig1_2_freq                 0\n",
      "sig1_2_price                0\n",
      "sig3_13_freq                0\n",
      "sig3_13_price               0\n",
      "sig3_12_freq                0\n",
      "                        ...  \n",
      "sig2_avg_price              0\n",
      "sig3_max_freq               0\n",
      "sig3_min_freq               0\n",
      "sig3_avg_freq               0\n",
      "sig3_max_price              0\n",
      "sig3_min_price              0\n",
      "sig3_avg_price              0\n",
      "sig4_max_freq               0\n",
      "sig4_min_freq               0\n",
      "sig4_avg_freq               0\n",
      "sig4_max_price              0\n",
      "sig4_min_price              0\n",
      "sig4_avg_price              0\n",
      "cost_in_description         0\n",
      "ft_0_name                   0\n",
      "ft_1_name                   0\n",
      "ft_2_name                   0\n",
      "ft_3_name                   0\n",
      "ft_4_name                   0\n",
      "ft_5_name                   0\n",
      "ft_6_name                   0\n",
      "name_clean                  0\n",
      "ft_0_desc                   0\n",
      "ft_1_desc                   0\n",
      "ft_2_desc                   0\n",
      "ft_3_desc                   0\n",
      "ft_4_desc                   0\n",
      "ft_5_desc                   0\n",
      "ft_6_desc                   0\n",
      "desc_clean                  0\n",
      "dtype: int64, train_id                    0\n",
      "name                        0\n",
      "item_condition_id           0\n",
      "category_name            1298\n",
      "brand_name             126465\n",
      "price                       0\n",
      "shipping                    0\n",
      "item_description            0\n",
      "log_price                   0\n",
      "category0                   0\n",
      "category1                   0\n",
      "category2                   0\n",
      "brand                       0\n",
      "sig3_10_freq                0\n",
      "sig3_10_price               0\n",
      "sig3_11_freq                0\n",
      "sig3_11_price               0\n",
      "sig2_5_freq                 0\n",
      "sig2_5_price                0\n",
      "sig1_0_freq                 0\n",
      "sig1_0_price                0\n",
      "sig4_14_freq                0\n",
      "sig4_14_price               0\n",
      "sig2_9_freq                 0\n",
      "sig2_9_price                0\n",
      "sig1_2_freq                 0\n",
      "sig1_2_price                0\n",
      "sig3_13_freq                0\n",
      "sig3_13_price               0\n",
      "sig3_12_freq                0\n",
      "                        ...  \n",
      "sig2_avg_price              0\n",
      "sig3_max_freq               0\n",
      "sig3_min_freq               0\n",
      "sig3_avg_freq               0\n",
      "sig3_max_price              0\n",
      "sig3_min_price              0\n",
      "sig3_avg_price              0\n",
      "sig4_max_freq               0\n",
      "sig4_min_freq               0\n",
      "sig4_avg_freq               0\n",
      "sig4_max_price              0\n",
      "sig4_min_price              0\n",
      "sig4_avg_price              0\n",
      "cost_in_description         0\n",
      "ft_0_name                   0\n",
      "ft_1_name                   0\n",
      "ft_2_name                   0\n",
      "ft_3_name                   0\n",
      "ft_4_name                   0\n",
      "ft_5_name                   0\n",
      "ft_6_name                   0\n",
      "name_clean                  0\n",
      "ft_0_desc                   0\n",
      "ft_1_desc                   0\n",
      "ft_2_desc                   0\n",
      "ft_3_desc                   0\n",
      "ft_4_desc                   0\n",
      "ft_5_desc                   0\n",
      "ft_6_desc                   0\n",
      "desc_clean                  0\n",
      "dtype: int64, test_id                     0\n",
      "name                        0\n",
      "item_condition_id           0\n",
      "category_name            3058\n",
      "brand_name             295525\n",
      "shipping                    0\n",
      "item_description            0\n",
      "category0                   0\n",
      "category1                   0\n",
      "category2                   0\n",
      "brand                       0\n",
      "sig3_10_freq                0\n",
      "sig3_10_price               0\n",
      "sig3_11_freq                0\n",
      "sig3_11_price               0\n",
      "sig2_5_freq                 0\n",
      "sig2_5_price                0\n",
      "sig1_0_freq                 0\n",
      "sig1_0_price                0\n",
      "sig4_14_freq                0\n",
      "sig4_14_price               0\n",
      "sig2_9_freq                 0\n",
      "sig2_9_price                0\n",
      "sig1_2_freq                 0\n",
      "sig1_2_price                0\n",
      "sig3_13_freq                0\n",
      "sig3_13_price               0\n",
      "sig3_12_freq                0\n",
      "sig3_12_price               0\n",
      "sig1_3_freq                 0\n",
      "                        ...  \n",
      "sig2_avg_price              0\n",
      "sig3_max_freq               0\n",
      "sig3_min_freq               0\n",
      "sig3_avg_freq               0\n",
      "sig3_max_price              0\n",
      "sig3_min_price              0\n",
      "sig3_avg_price              0\n",
      "sig4_max_freq               0\n",
      "sig4_min_freq               0\n",
      "sig4_avg_freq               0\n",
      "sig4_max_price              0\n",
      "sig4_min_price              0\n",
      "sig4_avg_price              0\n",
      "cost_in_description         0\n",
      "ft_0_name                   0\n",
      "ft_1_name                   0\n",
      "ft_2_name                   0\n",
      "ft_3_name                   0\n",
      "ft_4_name                   0\n",
      "ft_5_name                   0\n",
      "ft_6_name                   0\n",
      "name_clean                  0\n",
      "ft_0_desc                   0\n",
      "ft_1_desc                   0\n",
      "ft_2_desc                   0\n",
      "ft_3_desc                   0\n",
      "ft_4_desc                   0\n",
      "ft_5_desc                   0\n",
      "ft_6_desc                   0\n",
      "desc_clean                  0\n",
      "dtype: int64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   23.7s remaining:   35.6s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   25.4s finished\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.251008314467\n",
      "0.272391459233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "if 1==1:\n",
    "    cat_lookup=get_cat_lookup(datasets[0])\n",
    "    datasets=[clean_cat_brand(data) for data in datasets]\n",
    "    group_lookups=get_group_lookups(datasets[0])\n",
    "    vocabulary,keywords_raw,keywords_lookup=get_vocabulary(datasets[0])\n",
    "    datasets=[get_cat_brand_vars(data) for data in datasets]\n",
    "    for var,label in [('name','name'),('item_description','desc')]:\n",
    "        datasets=[get_free_text_vars(data,var,label) for data in datasets]\n",
    "    print ([data.isnull().sum() for data in datasets])\n",
    "    datasets=[clean_text(data) for data in datasets]\n",
    "    ins,oos,oot=datasets\n",
    "\n",
    "    sigs=[x for x in ins.columns if x[0:3] in ['sig','ft_']]+['shipping','item_condition_id','cost_in_description']\n",
    "    rfr=RandomForestRegressor(n_estimators=5,max_depth=20,min_samples_leaf=50,n_jobs=5,oob_score=True,verbose=1)\n",
    "    rfr.fit(ins[sigs],ins['log_price'])\n",
    "    ins['predicted_log_price1']=rfr.predict(ins[sigs])\n",
    "    oos['predicted_log_price1']=rfr.predict(oos[sigs].fillna(0))\n",
    "    oot['predicted_log_price1']=rfr.predict(oot[sigs].fillna(0))\n",
    "    datasets=[ins,oos,oot]\n",
    "    print (mean_squared_error(ins['log_price'].fillna(10),ins['predicted_log_price1']))\n",
    "    print (mean_squared_error(oos['log_price'].fillna(10),oos['predicted_log_price1']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets=[ins,oos,oot]\n",
    "#datasets=[ins.head(10000),oos.head(10000),oot.head(10000)]\n",
    "if 1==1:\n",
    "    sparse_features_columns=['name','item_description','brand','category_name']\n",
    "    sparse_features=[get_tfidf_matrix(datasets,column,30000) for column in sparse_features_columns]\n",
    "    sparse_features=[hstack(tuple(x)) for x in zip(*sparse_features)]\n",
    "    datasets=get_ridge_predictions(datasets,sparse_features,'predicted_log_price2')    \n",
    "    ins,oos,oot=datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named xgboost",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-887d792fd9ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/vaibhav.ojha2/xgboost-0.47'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named xgboost"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, os.path.join('/home/vaibhav.ojha2/xgboost-0.47'))\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5175           46.14m\n",
      "         2           0.5079           37.30m\n",
      "         3           0.4996           34.13m\n",
      "         4           0.4925           32.40m\n",
      "         5           0.4864           31.24m\n",
      "         6           0.4812           30.67m\n",
      "         7           0.4762           29.94m\n",
      "         8           0.4718           29.58m\n",
      "         9           0.4678           29.22m\n",
      "        10           0.4639           28.67m\n",
      "        20           0.4386           25.38m\n",
      "        30           0.4209           22.16m\n",
      "        40           0.4091           19.08m\n",
      "        50           0.3994           15.82m\n",
      "        60           0.3916           12.69m\n",
      "        70           0.3851            9.55m\n",
      "        80           0.3791            6.38m\n",
      "        90           0.3740            3.11m\n",
      "       100           0.3693            0.00s\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-ef2226c0677c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdepth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdatasets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_rf_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msparse_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'predicted_log_price%d'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'log_price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_log_price%d'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'log_price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_log_price%d'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-ef2226c0677c>\u001b[0m in \u001b[0;36mget_rf_predictions\u001b[0;34m(datasets, matrix, output_column, n_estimators)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'log_price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mft_feature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/arpit.goel/anaconda/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1849\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m         \"\"\"\n\u001b[0;32m-> 1851\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1852\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/arpit.goel/anaconda/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         array = _ensure_sparse_format(array, accept_sparse, dtype, copy,\n\u001b[0;32m--> 380\u001b[0;31m                                       force_all_finite)\n\u001b[0m\u001b[1;32m    381\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/arpit.goel/anaconda/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite)\u001b[0m\n\u001b[1;32m    241\u001b[0m     \"\"\"\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         raise TypeError('A sparse matrix was passed, but dense '\n\u001b[0m\u001b[1;32m    244\u001b[0m                         \u001b[0;34m'data is required. Use X.toarray() to '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                         'convert to a dense numpy array.')\n",
      "\u001b[0;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "def get_rf_predictions(datasets,matrix,output_column,n_estimators):\n",
    "    model = GradientBoostingRegressor(n_estimators=n_estimators,max_depth=3,verbose=1)\n",
    "    model.fit(matrix[0],datasets[0]['log_price'])\n",
    "    for i,ft_feature in enumerate(matrix):\n",
    "        datasets[i][output_column]=model.predict(ft_feature)\n",
    "    return datasets    \n",
    "\n",
    "for i,depth in enumerate([5,10,25,50,100]):\n",
    "    datasets=get_rf_predictions(datasets,sparse_features,'predicted_log_price%d'%(i+3),100)\n",
    "    print mean_squared_error(datasets[0]['log_price'].fillna(10),datasets[0]['predicted_log_price%d'%(i+3)])\n",
    "    print mean_squared_error(datasets[1]['log_price'].fillna(10),datasets[1]['predicted_log_price%d'%(i+3)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print datasets[i+1].columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_tfidf_matrix(datasets,column,num_features):\n",
    "    vectorizer = TfidfVectorizer(max_features=num_features) if num_features>0 else TfidfVectorizer()\n",
    "    ft_features=vectorizer.fit_transform(datasets[0][column].fillna('nan'))\n",
    "    return ft_features,vectorizer.vocabulary_\n",
    "\n",
    "def get_ridge_predictions(datasets,matrix,output_column):\n",
    "    model = Ridge(alpha=0.1,solver='sag')\n",
    "    model.fit(matrix,datasets[0]['log_price'])\n",
    "    return model\n",
    "\n",
    "sparse_features_columns=['name','item_description','brand','category_name']\n",
    "sparse_matrices=[get_tfidf_matrix(datasets,column,30000) for column in sparse_features_columns]\n",
    "sparse_features=hstack(tuple([x[0] for x in sparse_matrices]))\n",
    "vocabulary=['|'.join([y,z.encode('utf-8')]) for x,y in zip(sparse_matrices,sparse_features_columns) for z in x[1]]\n",
    "model=get_ridge_predictions(datasets,sparse_features,'predicted_log_price2')\n",
    "coefficients=pd.Series(model.coef_,index=vocabulary).to_csv('../02.Profile/8.LinearModelCoef.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1186028x65518 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 35100945 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name|nwt,-0.464671360315\r\n",
      "name|peacock,-0.315690256502\r\n",
      "name|all,-0.518345831848\r\n",
      "name|coach,-0.188012538811\r\n",
      "name|lace,-0.0666465888835\r\n",
      "name|chain,-0.276247253575\r\n",
      "name|limited,0.118325481754\r\n",
      "name|knotted,0.0560560391865\r\n",
      "name|dollar,-0.0312304551778\r\n",
      "name|lepidolite,0.0671520931889\r\n"
     ]
    }
   ],
   "source": [
    "!head ../02.Profile/8.LinearModelCoef.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.191534214111\n",
      "0.224883343535\n",
      "[ 0.31645587  0.          0.          0.          0.         -0.         -0.\n",
      " -0.         -0.         -0.          0.75376778]\n",
      "0.180593723406\n",
      "0.209746355956\n"
     ]
    }
   ],
   "source": [
    "if 1==1:\n",
    "    pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "    reg=Lasso(0.01)\n",
    "    all_predictions=['predicted_log_price%d'%(i+1) for i in range(11)]\n",
    "    reg.fit(ins[all_predictions],ins['log_price'])\n",
    "    ins['predicted_log_price']=reg.predict(ins[all_predictions])\n",
    "    oos['predicted_log_price']=reg.predict(oos[all_predictions].fillna(3))\n",
    "    oot['predicted_log_price']=reg.predict(oot[all_predictions].fillna(3))\n",
    "    print (mean_squared_error(ins['log_price'].fillna(10),ins['predicted_log_price11']))\n",
    "    print (mean_squared_error(oos['log_price'].fillna(10),oos['predicted_log_price11']))\n",
    "    print (reg.coef_)\n",
    "    print (mean_squared_error(ins['log_price'].fillna(10),ins['predicted_log_price']))\n",
    "    print (mean_squared_error(oos['log_price'].fillna(10),oos['predicted_log_price']))\n",
    "    \n",
    "    #oot['price']=np.exp(oot['predicted_log_price'])-1\n",
    "    #oot[['test_id','price']].fillna(10).to_csv('05.TextFeaturesEnsemble2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_price</th>\n",
       "      <th>predicted_log_price1</th>\n",
       "      <th>predicted_log_price2</th>\n",
       "      <th>predicted_log_price3</th>\n",
       "      <th>predicted_log_price4</th>\n",
       "      <th>predicted_log_price5</th>\n",
       "      <th>predicted_log_price6</th>\n",
       "      <th>predicted_log_price7</th>\n",
       "      <th>predicted_log_price8</th>\n",
       "      <th>predicted_log_price9</th>\n",
       "      <th>predicted_log_price10</th>\n",
       "      <th>predicted_log_price11</th>\n",
       "      <th>predicted_log_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>log_price</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted_log_price1</th>\n",
       "      <td>0.698</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted_log_price2</th>\n",
       "      <td>0.678</td>\n",
       "      <td>0.678</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted_log_price3</th>\n",
       "      <td>0.588</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.579</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted_log_price4</th>\n",
       "      <td>0.683</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.577</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted_log_price5</th>\n",
       "      <td>0.593</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.581</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted_log_price6</th>\n",
       "      <td>0.479</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.409</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted_log_price7</th>\n",
       "      <td>0.199</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.274</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted_log_price8</th>\n",
       "      <td>0.363</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.510</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted_log_price9</th>\n",
       "      <td>0.480</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.713</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted_log_price10</th>\n",
       "      <td>0.490</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.977</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted_log_price11</th>\n",
       "      <td>0.760</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.614</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted_log_price</th>\n",
       "      <td>0.781</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.973</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       log_price  predicted_log_price1  predicted_log_price2  \\\n",
       "log_price                  1.000                 0.698                 0.678   \n",
       "predicted_log_price1       0.698                 1.000                 0.678   \n",
       "predicted_log_price2       0.678                 0.678                 1.000   \n",
       "predicted_log_price3       0.588                 0.594                 0.579   \n",
       "predicted_log_price4       0.683                 0.680                 0.984   \n",
       "predicted_log_price5       0.593                 0.599                 0.578   \n",
       "predicted_log_price6       0.479                 0.665                 0.559   \n",
       "predicted_log_price7       0.199                 0.284                 0.221   \n",
       "predicted_log_price8       0.363                 0.519                 0.409   \n",
       "predicted_log_price9       0.480                 0.687                 0.530   \n",
       "predicted_log_price10      0.490                 0.699                 0.539   \n",
       "predicted_log_price11      0.760                 0.779                 0.869   \n",
       "predicted_log_price        0.781                 0.876                 0.844   \n",
       "\n",
       "                       predicted_log_price3  predicted_log_price4  \\\n",
       "log_price                             0.588                 0.683   \n",
       "predicted_log_price1                  0.594                 0.680   \n",
       "predicted_log_price2                  0.579                 0.984   \n",
       "predicted_log_price3                  1.000                 0.577   \n",
       "predicted_log_price4                  0.577                 1.000   \n",
       "predicted_log_price5                  0.981                 0.581   \n",
       "predicted_log_price6                  0.409                 0.557   \n",
       "predicted_log_price7                  0.198                 0.222   \n",
       "predicted_log_price8                  0.347                 0.409   \n",
       "predicted_log_price9                  0.457                 0.528   \n",
       "predicted_log_price10                 0.465                 0.537   \n",
       "predicted_log_price11                 0.759                 0.876   \n",
       "predicted_log_price                   0.737                 0.851   \n",
       "\n",
       "                       predicted_log_price5  predicted_log_price6  \\\n",
       "log_price                             0.593                 0.479   \n",
       "predicted_log_price1                  0.599                 0.665   \n",
       "predicted_log_price2                  0.578                 0.559   \n",
       "predicted_log_price3                  0.981                 0.409   \n",
       "predicted_log_price4                  0.581                 0.557   \n",
       "predicted_log_price5                  1.000                 0.409   \n",
       "predicted_log_price6                  0.409                 1.000   \n",
       "predicted_log_price7                  0.200                 0.274   \n",
       "predicted_log_price8                  0.348                 0.352   \n",
       "predicted_log_price9                  0.457                 0.375   \n",
       "predicted_log_price10                 0.466                 0.388   \n",
       "predicted_log_price11                 0.766                 0.604   \n",
       "predicted_log_price                   0.743                 0.590   \n",
       "\n",
       "                       predicted_log_price7  predicted_log_price8  \\\n",
       "log_price                             0.199                 0.363   \n",
       "predicted_log_price1                  0.284                 0.519   \n",
       "predicted_log_price2                  0.221                 0.409   \n",
       "predicted_log_price3                  0.198                 0.347   \n",
       "predicted_log_price4                  0.222                 0.409   \n",
       "predicted_log_price5                  0.200                 0.348   \n",
       "predicted_log_price6                  0.274                 0.352   \n",
       "predicted_log_price7                  1.000                 0.510   \n",
       "predicted_log_price8                  0.510                 1.000   \n",
       "predicted_log_price9                  0.379                 0.713   \n",
       "predicted_log_price10                 0.406                 0.737   \n",
       "predicted_log_price11                 0.251                 0.454   \n",
       "predicted_log_price                   0.243                 0.443   \n",
       "\n",
       "                       predicted_log_price9  predicted_log_price10  \\\n",
       "log_price                             0.480                  0.490   \n",
       "predicted_log_price1                  0.687                  0.699   \n",
       "predicted_log_price2                  0.530                  0.539   \n",
       "predicted_log_price3                  0.457                  0.465   \n",
       "predicted_log_price4                  0.528                  0.537   \n",
       "predicted_log_price5                  0.457                  0.466   \n",
       "predicted_log_price6                  0.375                  0.388   \n",
       "predicted_log_price7                  0.379                  0.406   \n",
       "predicted_log_price8                  0.713                  0.737   \n",
       "predicted_log_price9                  1.000                  0.977   \n",
       "predicted_log_price10                 0.977                  1.000   \n",
       "predicted_log_price11                 0.603                  0.614   \n",
       "predicted_log_price                   0.589                  0.600   \n",
       "\n",
       "                       predicted_log_price11  predicted_log_price  \n",
       "log_price                              0.760                0.781  \n",
       "predicted_log_price1                   0.779                0.876  \n",
       "predicted_log_price2                   0.869                0.844  \n",
       "predicted_log_price3                   0.759                0.737  \n",
       "predicted_log_price4                   0.876                0.851  \n",
       "predicted_log_price5                   0.766                0.743  \n",
       "predicted_log_price6                   0.604                0.590  \n",
       "predicted_log_price7                   0.251                0.243  \n",
       "predicted_log_price8                   0.454                0.443  \n",
       "predicted_log_price9                   0.603                0.589  \n",
       "predicted_log_price10                  0.614                0.600  \n",
       "predicted_log_price11                  1.000                0.973  \n",
       "predicted_log_price                    0.973                1.000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "oos[[x for x in oos.columns if 'log_price' in x]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAELCAYAAADJF31HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f568e29a590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_raw_train.groupby(np.floor(df_raw_train['train_id']/1000))['price'].mean().plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122        Sizes and info of clothes can be found on thei...\n",
      "290                               [rm] Discounted price [rm]\n",
      "932        1pc Oversize Turtle Neck Plaid Poncho Cape 1pc...\n",
      "1053       Minor play scratches Played with condition Tha...\n",
      "2158                          Please check to see if its all\n",
      "4729                                Bundle reserved for Evat\n",
      "4806       White and orange are both Baby Gap, blue strip...\n",
      "6580                                Bundle Free Shipping JEM\n",
      "6841       Just cleaning out my closet come with 2 tshirt...\n",
      "8025       (8) XXL 14x17 Shipping Polymailers (8) 10x13 P...\n",
      "8977                                         For andres andy\n",
      "9006       *this is an individual listing for 2 phone sta...\n",
      "9112       Triumph bra-free No flaws Used twice Sports br...\n",
      "11306      Swimsuit one piece bodysuit Bodysuit Dress-fre...\n",
      "11860                                     Here is the bundle\n",
      "12380      Bundle 3 brand new Milani eyeshadow palettes -...\n",
      "12802                                                ON HOLD\n",
      "13174                                          Price is firm\n",
      "13362                                     No description yet\n",
      "13966                                     No description yet\n",
      "15558                                                 Size 8\n",
      "15809      Four pieces. Three onesies and one pair of pan...\n",
      "16607                    10 vintage stained glass ornaments.\n",
      "16769      Jumping beans shorts set great condition/bundl...\n",
      "16778      Short lace front wig Gray wig Bra-free Deep sw...\n",
      "17077      22-Lululemon cropped pants with blue slightly ...\n",
      "18778      - Skin Perfector Pressed Opal - Skin Perfector...\n",
      "19130         A bundle of a striped jacket and faux fur vest\n",
      "19145                         29 items for Hello Everyone #2\n",
      "19351      Size 6 month baby girl dress from Carter's. Ch...\n",
      "                                 ...                        \n",
      "1458552            Bundle of magic 8 ball and Beer Money jar\n",
      "1458898    Dress Romper Eating cuff-free Skirt Bracelet-f...\n",
      "1459597    Brand new! 3 Victoria's Secret pink push-up br...\n",
      "1460998         Bundled Nike hoodie and under Armour jacket!\n",
      "1461701                                             Reserved\n",
      "1463520    Bundle for HelloEveryone #1, Purchase Date: 3....\n",
      "1463889    work/school computer bag 19x12 inches large Ma...\n",
      "1464023                                             10 items\n",
      "1464548                                   No description yet\n",
      "1467448                                   No description yet\n",
      "1468698                   3 baby items, new! Never been worn\n",
      "1469170                                         Bundle Saved\n",
      "1469443                                                  New\n",
      "1469819    New Maybelline Dream Wonder fluid touch Founda...\n",
      "1469850    Polar Edge brand rain coat Size small Smoke fr...\n",
      "1470284                                   No description yet\n",
      "1470714    Size: .16 fl oz Color: chihuahua Long wear lip...\n",
      "1472688    Mom jewellery set, School PJ's, jewelry displa...\n",
      "1474821                                      0-3 to 12 month\n",
      "1475507                                   No description yet\n",
      "1475521    Poetry camel romper size small. And Bebe Knit ...\n",
      "1476189                                                  New\n",
      "1476512        8GB Lexar memory card 8GB SanDisk flash drive\n",
      "1476545    Grey concrete suit with Black Polo M Jogger pa...\n",
      "1478076                                               Bundle\n",
      "1478182    Brand new! Victoria's Secret pink push-up bral...\n",
      "1479850    Cute woman's Columbia wind breaker size medium...\n",
      "1480139    Dress Dress Slip Dress Lingerie pleather-free ...\n",
      "1480496          See pictures :) thank you! Will ship Monday\n",
      "1482393                                                   :)\n",
      "Name: item_description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print df_raw_train[df_raw_train['name']=='Bundle']['item_description']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
