{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "os.chdir('C:/Users/arpit.goel/Documents/Projects/Kaggle/13.TrafficPrediction')\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "df_train=pd.read_csv('train_aWnotuB.csv',parse_dates=['DateTime'])\n",
    "df_test=pd.read_csv('test_BdBKkAj.csv',parse_dates=['DateTime'])\n",
    "\n",
    "monthly_regression_params={1: [2.93, 18.59], 2: [0.9, 6.18], 3: [0.5, 8.65], 4: [0.17, 5.19]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vars(df):\n",
    "    df['year']=df['DateTime'].dt.year\n",
    "    df['month']=df['DateTime'].dt.month\n",
    "    df['day']=df['DateTime'].dt.day\n",
    "    df['hour']=df['DateTime'].dt.hour\n",
    "    df['day_of_week']=df['DateTime'].dt.dayofweek\n",
    "    df['flag_sunday']=(df['day_of_week']==6).astype(np.int64)\n",
    "    df['flag_saturday']=(df['day_of_week']==5).astype(np.int64)\n",
    "    df['flag_friday']=(df['day_of_week']==4).astype(np.int64)\n",
    "    df['flag_monday']=(df['day_of_week']==0).astype(np.int64)\n",
    "    df['flag_weekday']=(df['day_of_week']<=4).astype(np.int64)\n",
    "    df['flag_junction_1']=(df['Junction']==1).astype(np.int64)\n",
    "    df['flag_junction_2']=(df['Junction']==2).astype(np.int64)\n",
    "    df['flag_junction_3']=(df['Junction']==3).astype(np.int64)\n",
    "    df['flag_junction_4']=(df['Junction']==4).astype(np.int64)\n",
    "    df['flag_last_day_of_month']=(df['day']==df['month'].map({1:31,2:28,3:31,4:30,5:31,6:30,7:31,8:31,9:30,10:31,11:30,12:31})).astype(np.int64)\n",
    "    df['encoded_month']=12*df['year']+df['month']-24191\n",
    "    df['encoded_day']=(df['DateTime']-date(2015,11,1)).dt.days\n",
    "    slope=df['Junction'].map(lambda x: monthly_regression_params[x][0])\n",
    "    intercept=df['Junction'].map(lambda x: monthly_regression_params[x][1])\n",
    "    df['monthly_avg']=intercept+slope*df['encoded_month']\n",
    "    return df\n",
    "\n",
    "train=get_vars(df_train)\n",
    "test=get_vars(df_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.5081680798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    48120.000000\n",
       "mean        22.009871\n",
       "std         18.315982\n",
       "min          1.000000\n",
       "1%           2.000000\n",
       "5%           4.000000\n",
       "10%          6.000000\n",
       "25%          9.000000\n",
       "50%         15.000000\n",
       "75%         29.000000\n",
       "90%         53.000000\n",
       "95%         70.000000\n",
       "99%         70.000000\n",
       "max         70.000000\n",
       "Name: Vehicles, dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print mean_squared_error(train['monthly_avg'], train['Vehicles'])\n",
    "train['Vehicles'].describe(percentiles=[0.01,0.05,0.1,0.25,0.5,0.75,0.9,0.95,0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monthly_avg               0.819338\n",
      "hour                      0.123669\n",
      "day_of_week               0.026190\n",
      "flag_weekday              0.020565\n",
      "flag_junction_2           0.005142\n",
      "month                     0.004228\n",
      "flag_junction_3           0.000868\n",
      "flag_last_day_of_month    0.000000\n",
      "flag_junction_4           0.000000\n",
      "flag_junction_1           0.000000\n",
      "flag_monday               0.000000\n",
      "flag_friday               0.000000\n",
      "flag_saturday             0.000000\n",
      "flag_sunday               0.000000\n",
      "dtype: float64\n",
      "5.94910161609\n",
      "6.99847163461\n"
     ]
    }
   ],
   "source": [
    "def model_train(df,test):\n",
    "    df=df.sort_values(by='DateTime')\n",
    "    df_train1=df.head(int(0.85*len(df)))\n",
    "    df_valid1=df.tail(len(df)-len(df_train1))\n",
    "    model_cols=['monthly_avg','month','hour','day_of_week']+[x for x in df.columns.tolist() if 'flag' in x]\n",
    "    regr = RandomForestRegressor(n_estimators=5, max_depth=5, random_state=0,min_samples_leaf=50,verbose=0)\n",
    "    regr.fit(df_train1[model_cols],df_train1['Vehicles'])\n",
    "    print pd.Series(regr.feature_importances_,index=model_cols).sort_values(ascending=False)\n",
    "    df['score']=regr.predict(df[model_cols])\n",
    "    df['error']=np.abs(df['score']-df['Vehicles'])\n",
    "    df['error_rank']=np.round(df['error'].rank(pct=True),3)\n",
    "    df.to_csv('chk1.csv')\n",
    "    print np.sqrt(mean_squared_error(regr.predict(df_train1[model_cols]), df_train1['Vehicles']))\n",
    "    print np.sqrt(mean_squared_error(regr.predict(df_valid1[model_cols]), df_valid1['Vehicles']))\n",
    "    return np.round(regr.predict(test[model_cols]))\n",
    "    \n",
    "test['Vehicles']=model_train(train,test)\n",
    "test[['ID','Vehicles']].to_csv('Model1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Just for preserving the code\n",
    "def model_train(df,test):\n",
    "    df=df.sort_values(by='DateTime')\n",
    "    df['rank']=df.groupby('Junction')['DateTime'].rank(ascending=True)\n",
    "    df['total']=df['Junction'].map(df['Junction'].value_counts())\n",
    "    df['Percentile']=1.0*df['rank']/df['total']\n",
    "    df_train1=df[df['Percentile']<0.85]\n",
    "    df_valid1=df[df['Percentile']>=0.85]\n",
    "    model_cols=['monthly_avg','month','hour','day_of_week']+[x for x in df.columns.tolist() if 'flag' in x]\n",
    "    print len(model_cols)\n",
    "    print model_cols\n",
    "    sm={}\n",
    "    for name, group in df_train1.groupby('Junction'):\n",
    "        regr = RandomForestRegressor(n_estimators=10, max_depth=10, random_state=0,min_samples_leaf=50,verbose=0)\n",
    "        if name==4:\n",
    "            model_cols.remove('month')\n",
    "        regr.fit(group[model_cols],group['Vehicles'])\n",
    "        feature_importance=pd.Series(regr.feature_importances_,index=model_cols).sort_values(ascending=False)\n",
    "        feature_importance=feature_importance.cumsum()\n",
    "        new_cols=feature_importance[feature_importance<0.99].index\n",
    "        regr = RandomForestRegressor(n_estimators=1, max_depth=10, random_state=0,min_samples_leaf=50,verbose=0)\n",
    "        regr.fit(group[new_cols],group['Vehicles'])\n",
    "        feature_importance=pd.Series(regr.feature_importances_,index=new_cols).sort_values(ascending=False)\n",
    "        print feature_importance\n",
    "        sm[name]=[new_cols,regr]\n",
    "        \n",
    "    all_scores=[pd.Series(sm[name][1].predict(group[sm[name][0]]),index=group['ID']) for name,group in df.groupby('Junction')]\n",
    "    all_scores=np.round(pd.concat(all_scores))\n",
    "    df['score']=df['ID'].map(all_scores)\n",
    "    df['error']=np.abs(df['score']-df['Vehicles'])\n",
    "    df['error_rank']=np.round(df['error'].rank(pct=True),3)\n",
    "    df.to_csv('chk1.csv')\n",
    "    print np.sqrt(mean_squared_error(df_train1['ID'].map(all_scores), df_train1['Vehicles']))\n",
    "    print np.sqrt(mean_squared_error(df_valid1['ID'].map(all_scores), df_valid1['Vehicles']))\n",
    "    test_scores=pd.concat([pd.Series(sm[name][1].predict(group[sm[name][0]]),index=group['ID']) for name,group in test.groupby('Junction')])\n",
    "    test_scores=np.round(test_scores)\n",
    "    regr = RandomForestRegressor(n_estimators=10, max_depth=10, random_state=0,min_samples_leaf=50,verbose=0)\n",
    "    regr.fit(train[model_cols],train['Vehicles'])\n",
    "    test['Vehicles']=np.round(regr.predict(test[model_cols]))\n",
    "    test_scores=pd.Series(test['Vehicles'],index=test['ID'])\n",
    "    return test_scores\n",
    "    \n",
    "test['Vehicles']=test['ID'].map(model_train(train,test))\n",
    "test[['ID','Vehicles']].to_csv('Model1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ins' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d46e7ce2fb2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimp_days\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Junction'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'encoded_date'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Vehicles'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mimp_days_prev\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoded_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimp_days\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoded_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimp_days\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimp_days\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimp_days_prev\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Junction'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'encoded_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimp_days\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Delta'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimp_days\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Vehicles_x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mimp_days\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Vehicles_y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ins' is not defined"
     ]
    }
   ],
   "source": [
    "imp_days=ins[['Junction','encoded_date','Vehicles']]\n",
    "imp_days_prev['encoded_date']=imp_days['encoded_date']+1\n",
    "imp_days=pd.merge(imp_days,imp_days_prev,on=['Junction','encoded_date'])\n",
    "imp_days['Delta']=imp_days['Vehicles_x']/imp_days['Vehicles_y']-1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
