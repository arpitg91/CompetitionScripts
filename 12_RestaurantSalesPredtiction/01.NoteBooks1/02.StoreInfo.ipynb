{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arpit.goel\\AppData\\Local\\Continuum2\\Anaconda2\\lib\\site-packages\\IPython\\utils\\py3compat.py:279: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->block1_values] [items->['air_store_id', 'cuisine', 'area_type', 'cluster', 'visit_date', 'reserve_date']]\n",
      "\n",
      "  exec(compiler(scripttext, filename, 'exec'), glob, loc)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "os.chdir('C:/Users/arpit.goel/Documents/Projects/Kaggle/15.RecruitRestarauntPrediction')\n",
    "\n",
    "%run 00.Scripts/01.DataImport.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime,date,timedelta\n",
    "from itertools import product\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "os.chdir('C:/Users/arpit.goel/Documents/Projects/Kaggle/15.RecruitRestarauntPrediction')\n",
    "store=pd.HDFStore('01.RawData/DataStore.h5')\n",
    "store['air_visit_data']=pd.read_csv('01.RawData/air_visit_data.csv',parse_dates=['visit_date'],index_col=['air_store_id','visit_date'])\n",
    "store['date_info']=pd.read_csv('01.RawData/date_info.csv',parse_dates=['calendar_date'],index_col=['calendar_date'])\n",
    "store['store_id_relation']=pd.read_csv('01.RawData/store_id_relation.csv')\n",
    "\n",
    "#Get store info master data\n",
    "df=pd.read_csv('01.RawData/hpg_store_info.csv',index_col=['hpg_store_id'])\n",
    "df=pd.merge(df, store['store_id_relation'], how='left', left_index=True,right_on=['hpg_store_id'])\n",
    "df.index=df['air_store_id'].fillna(df['hpg_store_id'])\n",
    "df2=pd.read_csv('01.RawData/air_store_info.csv',index_col=['air_store_id'])\n",
    "cuisine_mapping=pd.read_csv('01.RawData/cuisine_mapping.csv',index_col=['cuisine'])\n",
    "cuisine_mapping=cuisine_mapping['mapping'].str.lower()\n",
    "store_info=pd.concat([df2,df])\n",
    "store_info['cuisine']=store_info['air_genre_name'].fillna(store_info['hpg_genre_name']).map(cuisine_mapping)\n",
    "store_info['area_name']=store_info['air_area_name'].fillna(store_info['hpg_area_name'])\n",
    "store_info['flag_prefecture']=store_info['area_name'].map(lambda x: '-to' in x or '-do' in x or '-fu' in x or '-ken' in x or 'Prefecture' in x or '-gun' in x).astype(np.int8)\n",
    "store_info['flag_city']=store_info['area_name'].map(lambda x: '-shi' in x).astype(np.int8)\n",
    "store_info['area_type']=store_info['flag_prefecture'].astype(np.str)+store_info['flag_city'].astype(np.str)\n",
    "store_info[[x for x in store_info.columns if 'flag' in x]].apply(lambda x: '-'.join(map(str,x)),axis=1).value_counts()\n",
    "store_info['cluster']= KMeans(n_clusters=10, random_state=0).fit(store_info[['latitude','longitude']]).labels_\n",
    "store['store_info']=store_info[['cuisine','area_type','cluster']].groupby(level=0).first()\n",
    "\n",
    "#Get reservation master data\n",
    "df=pd.read_csv('01.RawData/air_reserve.csv',parse_dates=['visit_datetime','reserve_datetime'],index_col=['air_store_id'])\n",
    "df['type']='air'\n",
    "df2=pd.read_csv('01.RawData/hpg_reserve.csv',parse_dates=['visit_datetime','reserve_datetime'],index_col=['hpg_store_id'])\n",
    "df2=pd.merge(df2, store['store_id_relation'], how='left', left_index=True,right_on=['hpg_store_id'])\n",
    "df2.index=df2['air_store_id'].fillna(df2['hpg_store_id'])\n",
    "df2['type']='hpg'\n",
    "df=pd.concat([df,df2])\n",
    "df['visit_date']=df['visit_datetime'].dt.date\n",
    "df['reserve_date']=df['reserve_datetime'].dt.date\n",
    "df=df[df['visit_date']>=date(2016,12,31)]\n",
    "df=df[['reserve_visitors','type','visit_date','reserve_date']].reset_index()\n",
    "df=np.log1p(df.groupby(['air_store_id','visit_date','reserve_date','type'])['reserve_visitors'].sum()).reset_index()\n",
    "df=pd.merge(df,store['store_info'],left_on=['air_store_id'],right_index=True,how='left')\n",
    "reservation_groups=[]\n",
    "reservation_groups.append(df.groupby(['cluster','visit_date','reserve_date','type'])['reserve_visitors'].sum().unstack())\n",
    "reservation_groups.append(df.groupby(['cluster','cuisine','visit_date','reserve_date','type'])['reserve_visitors'].sum().unstack())\n",
    "reservation_groups.append(df.groupby(['cluster','area_type','visit_date','reserve_date','type'])['reserve_visitors'].sum().unstack())\n",
    "reservation_groups.append(df.groupby(['cluster','cuisine','area_type','visit_date','reserve_date','type'])['reserve_visitors'].sum().unstack())\n",
    "reservation_groups.append(df.groupby(['air_store_id','cluster','cuisine','area_type','visit_date','reserve_date','type'])['reserve_visitors'].sum().unstack())\n",
    "df2=store['store_info'].reset_index()\n",
    "df2=df2[df2['air_store_id'].str[:3]=='air']\n",
    "for i in range(len(reservation_groups)):\n",
    "    reservation_groups[i].columns=['reserve_%d_%s'%(i,x) for x in reservation_groups[i].columns]\n",
    "    reservation_groups[i]=reservation_groups[i].reset_index()\n",
    "    keys=reservation_groups[i].reset_index().columns.intersection(df2.columns).tolist()\n",
    "    df2=pd.merge(df2,reservation_groups[i],on=keys,how='left')\n",
    "store['reserve_master']=df2\n",
    "\n",
    "# Read sample submission\n",
    "df=pd.read_csv('01.RawData/sample_submission.csv')\n",
    "df['air_store_id']=df['id'].map(lambda x: '_'.join(x.split('_')[:2]))\n",
    "df['visit_date']=pd.to_datetime(df['id'].map(lambda x: x.split('_')[2]))\n",
    "df.set_index(['air_store_id','visit_date'],inplace=True)\n",
    "store['sample_submission']=df\n",
    "\n",
    "#Get visits master data\n",
    "df=pd.merge(np.log1p(store['air_visit_data']).reset_index(),store['store_info'],left_on=['air_store_id'],right_index=True)\n",
    "df=df[df['visit_date']<date(2016,6,1)]\n",
    "visits_groups=[]\n",
    "visits_groups.append(df.groupby(['cluster','visit_date'])['visitors'].sum().to_frame('visits_0').reset_index())\n",
    "visits_groups.append(df.groupby(['cluster','cuisine','visit_date'])['visitors'].sum().to_frame('visits_1').reset_index())\n",
    "visits_groups.append(df.groupby(['cluster','area_type','visit_date'])['visitors'].sum().to_frame('visits_2').reset_index())\n",
    "visits_groups.append(df.groupby(['cluster','area_type','cuisine','visit_date'])['visitors'].sum().to_frame('visits_3').reset_index())\n",
    "visits_groups.append(df.groupby(['air_store_id','visit_date'])['visitors'].sum().to_frame('visits_4').reset_index())\n",
    "df2=store['store_info'].reset_index()\n",
    "df2=df2[df2['air_store_id'].str[:3]=='air']\n",
    "for i in range(len(reservation_groups)):\n",
    "    keys=visits_groups[i].reset_index().columns.intersection(df2.columns).tolist()\n",
    "    df2=pd.merge(df2,visits_groups[i],on=keys,how='left')\n",
    "store['visit_master']=df2[['air_store_id','visit_date','visits_0','visits_1','visits_2','visits_3','visits_4']]\n",
    "\n",
    "# store.close()    \n",
    "# store={}\n",
    "# for file in ['air_reserve','air_store_info','air_visit_data','date_info','hpg_reserve','hpg_store_info','store_id_relation','sample_submission']:\n",
    "    # store[file]=pd.read_hdf('01.RawData/DataStore.h5', file)\n",
    "\n",
    "visits=np.log1p(pd.concat([store['air_visit_data'],store['sample_submission']])['visitors']).unstack()\n",
    "min_dates=visits.stack().reset_index().groupby(['air_store_id'])['visit_date'].min()\n",
    "min_dates.name='first_date'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data_single_model():\n",
    "    baseline_pred_vars=['avg_visitors_wd_21','med_visitors_wd_21','cnt_visitors_147','avg_visitors_7','med_visitors_wd_13',\\\n",
    "                    'cnt_visitors_wd_13','avg_visitors_wd_10','avg_visitors_3','min_visitors_wd_21','min_visitors_wd_5',\\\n",
    "                    'med_visitors_wd_10','min_visitors_wd_1','avg_visitors_wd_13','cnt_visitors_wd_21','min_visitors_3',\\\n",
    "                    'med_visitors_3','cnt_visitors_7','max_visitors_147','med_visitors_7','med_visitors_wd_8','avg_visitors_wd_2',\\\n",
    "                    'min_visitors_21','avg_visitors_wd_8','min_visitors_91','max_visitors_56','min_visitors_7','avg_visitors_21',\\\n",
    "                    'max_visitors_42','cnt_visitors_91']\n",
    "    other_vars=['reserve_%d_%s'%(x,y) for x,y in product(range(5),['air','hpg'])]\n",
    "    other_vars+=['visits_%d_%d'%(x,y) for x,y in product([364,365],range(5))]\n",
    "    output=[[],[],[],[],[]]\n",
    "    for i in range(39):\n",
    "        ins_msk=store['train_y'].iloc[:,i].fillna(0)>0\n",
    "        oos_msk=store['val_y'].iloc[:,i].fillna(0)>0\n",
    "        idv=['%s_visitors_%d'%(x,y) for x,y in product(['min','max','avg','med','cnt'],[1,2,3,7,14,21,35,42,56,91,147])]\n",
    "        idv+=['%s_visitors_wd%d_%d'%(x,6-i%7,y) for x,y in product(['min','max','avg','med','cnt'],[1,2,3,5,8,10,13,21])]\n",
    "        idv+=['reserve_%d_%s_%d'%(x,y,i) for x,y in product(range(5),['air','hpg'])]\n",
    "        idv+=['visits_%d_%d_%d'%(x,y,i) for x,y in product([364,365],range(5))]\n",
    "        idv_labels=['%s_visitors_%d'%(x,y) for x,y in product(['min','max','avg','med','cnt'],[1,2,3,7,14,21,35,42,56,91,147])]\n",
    "        idv_labels+=['%s_visitors_wd_%d'%(x,y) for x,y in product(['min','max','avg','med','cnt'],[1,2,3,5,8,10,13,21])]\n",
    "        idv_labels+=['reserve_%d_%s'%(x,y) for x,y in product(range(5),['air','hpg'])]\n",
    "        idv_labels+=['visits_%d_%d'%(x,y) for x,y in product([364,365],range(5))]\n",
    "        dfs=[]\n",
    "        dfs.append(store['train_x'].loc[ins_msk,idv].rename(columns=dict(zip(idv,idv_labels)))[baseline_pred_vars+other_vars])\n",
    "        dfs.append(store['val_x'].loc[oos_msk,idv].rename(columns=dict(zip(idv,idv_labels)))[baseline_pred_vars+other_vars])\n",
    "        dfs.append(store['test_x'].loc[:,idv].rename(columns=dict(zip(idv,idv_labels)))[baseline_pred_vars+other_vars])\n",
    "        dfs.append(store['train_y'].loc[ins_msk,i].to_frame('tgt'))\n",
    "        dfs.append(store['val_y'].loc[oos_msk,i].to_frame('tgt'))\n",
    "        for j in range(5):\n",
    "            dfs[j]['day']=i\n",
    "            output[j].append(dfs[j])\n",
    "    output=[pd.concat(x) for x in output]\n",
    "    return output\n",
    "\n",
    "    \n",
    "data=[prepare_dataset(i.date()) for i in pd.date_range(date(2016,12,31),periods=11,freq='7D')]\n",
    "X,Y=zip(*data)\n",
    "store['train_x']=pd.concat(list(X)[:-1])\n",
    "store['train_y']=pd.concat(list(Y)[:-1])\n",
    "store['val_x']=X[-1]\n",
    "store['val_y']=Y[-1]\n",
    "store['test_x']=prepare_dataset(date(2017,4,22))\n",
    "\n",
    "data=prepare_data_single_model()\n",
    "for x,y in zip(['train1_x','val1_x','test1_x','train1_y','val1_y'],data):\n",
    "    store[x]=y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def prepare_dataset(dt):\n",
    "    features={}\n",
    "    for i in [1,2,3,7,14,21,35,42,56,91,147]:\n",
    "        dcut=get_timespan(visits,dt,i)\n",
    "        features['avg_visitors_%d'%i]=dcut.mean(axis=1).values\n",
    "        features['min_visitors_%d'%i]=dcut.min(axis=1).values\n",
    "        features['max_visitors_%d'%i]=dcut.max(axis=1).values\n",
    "        features['med_visitors_%d'%i]=dcut.median(axis=1).values\n",
    "        features['cnt_visitors_%d'%i]=dcut.count(axis=1).values\n",
    "    for i,j in product(range(7),[1,2,3,5,8,10,12,13,21]):\n",
    "        dcut=get_timespan(visits,dt-timedelta(days=i),j,7)\n",
    "        features['avg_visitors_wd%d_%d'%(i,j)]=dcut.mean(axis=1).values\n",
    "        features['min_visitors_wd%d_%d'%(i,j)]=dcut.min(axis=1).values\n",
    "        features['max_visitors_wd%d_%d'%(i,j)]=dcut.max(axis=1).values\n",
    "        features['med_visitors_wd%d_%d'%(i,j)]=dcut.median(axis=1).values\n",
    "        features['cnt_visitors_wd%d_%d'%(i,j)]=dcut.count(axis=1).values\n",
    "        \n",
    "    visits=store['visit_master']\n",
    "    visits=visits[visits['visit_date']>=dt+timedelta(-365)]\n",
    "    visits=visits[visits['visit_date']<=dt+timedelta(40-365)]\n",
    "    for j in range(5):\n",
    "        visits1=visits.set_index(['air_store_id','visit_date'])['visits_%d'%j].unstack().reindex(visits.index)\n",
    "        for i in range(39):\n",
    "            features['visits_365_%d_%d'%(j,i)]=visits1.iloc[:,i].values\n",
    "            features['visits_364_%d_%d'%(j,i)]=visits1.iloc[:,i+1].values\n",
    "        \n",
    "    reserve=store['reserve_master']\n",
    "    reserve=reserve[reserve['reserve_date']<dt]\n",
    "    reserve=reserve[reserve['visit_date']>=dt]\n",
    "    reserve=reserve[reserve['visit_date']<=dt+timedelta(39)]\n",
    "    for j,k in product(range(5),['air','hpg']):\n",
    "        reserve1=reserve.groupby(['air_store_id','visit_date'])['reserve_%d_%s'%(j,k)].sum().unstack().reindex(visits.index)\n",
    "        for i in range(39):\n",
    "            if dt+timedelta(days=i) in reserve1.columns:\n",
    "                features['reserve_%d_%s_%d'%(j,k,i)]=reserve1[dt+timedelta(days=i)].values\n",
    "    X=pd.DataFrame(features,index=visits.index)\n",
    "    if (dt-date(2017,4,22)).days<0:\n",
    "        y=visits[pd.date_range(dt+timedelta(days=1),periods=39)].values\n",
    "        y=pd.DataFrame(y,index=visits.index)\n",
    "        return X,y\n",
    "    return X\n",
    "\n",
    "visits=np.log1p(pd.concat([store['air_visit_data'],store['sample_submission']])['visitors']).unstack()\n",
    "min_dates=visits.stack().reset_index().groupby(['air_store_id'])['visit_date'].min()\n",
    "min_dates.name='first_date'\n",
    "\n",
    "\n",
    "prepare_dataset(date(2017,4,22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.merge(np.log1p(store['air_visit_data']).reset_index(),store['store_info'],left_on=['air_store_id'],right_index=True)\n",
    "df=df[df['visit_date']>=date(2017,1,1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('03.Profile/1.Visitors_Daily.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
